{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchEngine():\n",
    "    \"\"\"Search engine for the News Feed website, which takes a search term and optional start and finish dates to produce relevant news items.\"\"\"\n",
    "\n",
    "    def generate_search_url(self, search_term, from_date=None, to_date=None):\n",
    "        \"\"\"\n",
    "        Generates a search URL for the given search term and data filter.\n",
    "        \"\"\"\n",
    "        if from_date and not to_date:\n",
    "            # no to date, default to a timeframe of 10 days\n",
    "            to_date = from_date + timedelta(days=10)\n",
    "        elif to_date and not from_date:\n",
    "            # no from date, default to a timeframe of 10 days\n",
    "            from_date = to_date - timedelta(days=10)\n",
    "        elif not to_date and not from_date:\n",
    "            # neither exist, default to a timeframe of the past 10 days\n",
    "            to_date = datetime.today()\n",
    "            from_date = to_date - timedelta(days=10)\n",
    "        time_filter = f'after:{from_date.strftime(\"%Y-%m-%d\")} before:{to_date.strftime(\"%Y-%m-%d\")}'\n",
    "        url = f'https://news.google.com/rss/search?q={search_term}+{time_filter}&hl=en-US&gl=US&ceid=US:en'\n",
    "        return url\n",
    "\n",
    "    def get_text(self, description):\n",
    "        \"\"\"\n",
    "        Extracts the text from a description string.\n",
    "        \"\"\"\n",
    "        start = description.find('<p>') + 3\n",
    "        end = description.find('</p>')\n",
    "        return description[start:end]\n",
    "\n",
    "    def parse_news_items(self, root):\n",
    "        \"\"\"\n",
    "        Parses the news items from the XML root element.\n",
    "        \"\"\"\n",
    "        news_items = []\n",
    "        for item in root.findall('.//channel/item'):\n",
    "            title = item.find('title').text\n",
    "            link = item.find('link').text\n",
    "            description = self.get_text(item.find('description').text)\n",
    "            pub_date = pd.to_datetime(item.find('pubDate').text)\n",
    "            source = item.find('source').text\n",
    "            news_item = {\n",
    "                'title': title,\n",
    "                'link': link,\n",
    "                'description': description,\n",
    "                'pub_date': pub_date,\n",
    "                'source': source\n",
    "            }\n",
    "            news_items.append(news_item)\n",
    "        return news_items\n",
    "\n",
    "    def get_news(self, search_term, from_date, to_date):\n",
    "        \"\"\"\n",
    "        Searches Google News for the given search term and data filter, and returns\n",
    "        a DataFrame containing the news items.\n",
    "        \"\"\"\n",
    "        url = self.generate_search_url(search_term, from_date, to_date)\n",
    "        print(url)\n",
    "        response = requests.get(url)\n",
    "        if response.status_code != 200:\n",
    "            raise Exception('Failed to fetch news items.')\n",
    "        root = ET.fromstring(response.text)\n",
    "        news_items = self.parse_news_items(root)\n",
    "        df = pd.DataFrame(news_items)\n",
    "        df.to_csv(f'{search_term}_news.csv', encoding='utf-8-sig', index=False)\n",
    "        return df\n",
    "    \n",
    "    def search(self, search_term, from_date=None, to_date=None):\n",
    "        data = self.get_news(search_term, from_date, to_date)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                title  \\\n",
      "0   Kansas City Chiefs superfan who became a fugit...   \n",
      "1   Kansas City Chiefs superfan 'ChiefsAholic' arr...   \n",
      "2   K.C. Chiefs superfan went on bank robbery spre...   \n",
      "3   Atlanta Nail First salon robbery ends with cus...   \n",
      "4   Nail salon robbery goes awry as customers comp...   \n",
      "..                                                ...   \n",
      "87  Man robbed, hit by vehicle after leaving North...   \n",
      "88  (UPDATE) Police Seek Public's Help in Locating...   \n",
      "89  MPD seeks publicâ€™s help finding Waffle House r...   \n",
      "90  Armed suspects steal $15k during armored truck...   \n",
      "91  60 shots, 2 wounded, 1 dead, 6 arrested after ...   \n",
      "\n",
      "                                                 link  \\\n",
      "0   https://news.google.com/rss/articles/CBMiXGh0d...   \n",
      "1   https://news.google.com/rss/articles/CBMiigFod...   \n",
      "2   https://news.google.com/rss/articles/CBMifmh0d...   \n",
      "3   https://news.google.com/rss/articles/CBMicmh0d...   \n",
      "4   https://news.google.com/rss/articles/CBMiWWh0d...   \n",
      "..                                                ...   \n",
      "87  https://news.google.com/rss/articles/CBMiiAFod...   \n",
      "88  https://news.google.com/rss/articles/CBMiSGh0d...   \n",
      "89  https://news.google.com/rss/articles/CBMiWWh0d...   \n",
      "90  https://news.google.com/rss/articles/CBMia2h0d...   \n",
      "91  https://news.google.com/rss/articles/CBMibGh0d...   \n",
      "\n",
      "                                          description  \\\n",
      "0    href=\"https://news.google.com/rss/articles/CB...   \n",
      "1    href=\"https://news.google.com/rss/articles/CB...   \n",
      "2    href=\"https://news.google.com/rss/articles/CB...   \n",
      "3    href=\"https://news.google.com/rss/articles/CB...   \n",
      "4    href=\"https://news.google.com/rss/articles/CB...   \n",
      "..                                                ...   \n",
      "87   href=\"https://news.google.com/rss/articles/CB...   \n",
      "88   href=\"https://news.google.com/rss/articles/CB...   \n",
      "89   href=\"https://news.google.com/rss/articles/CB...   \n",
      "90   href=\"https://news.google.com/rss/articles/CB...   \n",
      "91   href=\"https://news.google.com/rss/articles/CB...   \n",
      "\n",
      "                    pub_date            source  \n",
      "0  2023-07-11 07:00:00+00:00               CNN  \n",
      "1  2023-07-10 07:00:00+00:00         USA TODAY  \n",
      "2  2023-07-13 14:42:56+00:00      Star Tribune  \n",
      "3  2023-07-07 07:00:00+00:00         USA TODAY  \n",
      "4  2023-07-07 07:00:00+00:00               CNN  \n",
      "..                       ...               ...  \n",
      "87 2023-06-14 07:00:00+00:00  KSAT San Antonio  \n",
      "88 2023-06-01 07:00:00+00:00       seattle.gov  \n",
      "89 2023-06-15 07:00:00+00:00       Fox 10 News  \n",
      "90 2023-06-10 07:00:00+00:00          CBS News  \n",
      "91 2023-06-23 07:00:00+00:00   Tampa Bay Times  \n",
      "\n",
      "[92 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "class ArticleParser():\n",
    "    \"\"\"Class that contains the functions to parse one article given\"\"\"\n",
    "\n",
    "    def __init__(self, link):\n",
    "        self.link = link\n",
    "        html_text = requests.get(self.link)\n",
    "        soup = BeautifulSoup(html_text.content.decode('utf-8'))\n",
    "        self.title = soup.find('title')\n",
    "        body = soup.find_all('p')\n",
    "        lists = soup.find_all('li')\n",
    "        self.text = ' '.join([p.text for p in body]) + \" \" + ' '.join([p.text for p in lists])\n",
    "\n",
    "    def graph(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def summarize(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def sentiment(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def bias(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def to_csv(self):\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
