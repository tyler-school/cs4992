{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Odx-5xW78vJg",
        "outputId": "7f4bc9f4-d3d3-4542-c262-24a525d9080a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n",
            "{}\n"
          ]
        }
      ],
      "source": [
        "#Libraries\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "TODAY = datetime.today().strftime('%Y-%m-%d')\n",
        "YESTERDAY = (datetime.today() - timedelta(days=1)).strftime('%Y-%m-%d')\n",
        "THIS_WEEK = (datetime.today() - timedelta(days=7)).strftime('%Y-%m-%d')\n",
        "\n",
        "def generate_search_url(search_term, data_filter=None):\n",
        "    \"\"\"\n",
        "    Generates a search URL for the given search term and data filter.\n",
        "    \"\"\"\n",
        "    if data_filter == 'today':\n",
        "        time_filter = f'after:{YESTERDAY}'\n",
        "    elif data_filter == 'this_week':\n",
        "        time_filter = f'after:{THIS_WEEK} before:{TODAY}'\n",
        "    elif data_filter == 'this_year':\n",
        "        time_filter = f'after:{pd.datetime.today().year - 1}'\n",
        "    elif isinstance(data_filter, int):\n",
        "        temp_time = (pd.datetime.today() - pd.Timedelta(days=data_filter)).strftime('%Y-%m-%d')\n",
        "        time_filter = f'after:{temp_time} before:{TODAY}'\n",
        "    else:\n",
        "        time_filter = ''\n",
        "    url = f'https://news.google.com/rss/search?q={search_term}+{time_filter}&hl=en-US&gl=US&ceid=US:en'\n",
        "    return url\n",
        "\n",
        "def get_text(description):\n",
        "    \"\"\"\n",
        "    Extracts the text from a description string.\n",
        "    \"\"\"\n",
        "    start = description.find('<p>') + 3\n",
        "    end = description.find('</p>')\n",
        "    return description[start:end]\n",
        "\n",
        "def parse_news_items(root):\n",
        "    \"\"\"\n",
        "    Parses the news items from the XML root element.\n",
        "    \"\"\"\n",
        "    news_items = []\n",
        "    for item in root.findall('.//channel/item'):\n",
        "        title = item.find('title').text\n",
        "        link = item.find('link').text\n",
        "        description = get_text(item.find('description').text)\n",
        "        pub_date = pd.to_datetime(item.find('pubDate').text)\n",
        "        source = item.find('source').text\n",
        "        news_item = {\n",
        "            'title': title,\n",
        "            'link': link,\n",
        "            'description': description,\n",
        "            'pub_date': pub_date,\n",
        "            'source': source\n",
        "        }\n",
        "        news_items.append(news_item)\n",
        "    return news_items\n",
        "\n",
        "def get_news(search_term, data_filter=None):\n",
        "    \"\"\"\n",
        "    Searches Google News for the given search term and data filter, and returns\n",
        "    a DataFrame containing the news items.\n",
        "    \"\"\"\n",
        "    url = generate_search_url(search_term, data_filter)\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        raise Exception('Failed to fetch news items.')\n",
        "    root = ET.fromstring(response.text)\n",
        "    news_items = parse_news_items(root)\n",
        "    df = pd.DataFrame(news_items)\n",
        "    df.to_csv(f'{search_term}_news.csv', encoding='utf-8-sig', index=False)\n",
        "    return df\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     start_time = time.time()\n",
        "#     search_term = input('Enter your search term here: ')\n",
        "#     data_filter = int(input('Enter number of days ago or leave blank for all data: ')) or None\n",
        "#     data = get_news(search_term, data_filter)\n",
        "#     end_time = time.time()\n",
        "#     print(f'Execution time: {end_time - start_time:.2f} seconds')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    search_term = \"northeastern university\"\n",
        "    data_filter = None\n",
        "    url = generate_search_url(search_term, data_filter)\n",
        "    response = requests.get(url)\n",
        "    root = ET.fromstring(response.text)\n",
        "    for item in root.findall('.//channel/item'):\n",
        "        print(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHnVVZ_VOKRK"
      },
      "source": [
        "Sentiment\n",
        "Polarity\n",
        "Subjectivity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JO1Bvlknkk06"
      },
      "source": [
        "This script does the following:\n",
        "\n",
        "It prompts the user to input a search term and a number of past days to search. The number of past days acts as a filter to retrieve only the recent news related to the given search term.\n",
        "\n",
        "Using the get_news function, it makes a request to Google News RSS feed with the specified search term and filters the articles based on the provided date.\n",
        "\n",
        "The get_news function parses the XML response from the request, extracts useful information from each news article, and stores it in a list of dictionaries.\n",
        "\n",
        "The script then uses the get_sentiment function to analyze the sentiment of the description of each news article using TextBlob. It computes the polarity and subjectivity of the text. The polarity score is a float between -1.0 and 1.0 where -1.0 means a negative sentiment and 1.0 means a positive sentiment. The subjectivity is a float between 0.0 and 1.0 where 0.0 is very objective and 1.0 is very subjective.\n",
        "\n",
        "Finally, it prints the title, description, and sentiment (polarity and subjectivity) of each news article."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-0TrIyy09eoh"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     /Users/luisali/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dGY04hm-C9z"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "import time\n",
        "from textblob import TextBlob\n",
        "\n",
        "\n",
        "def generate_search_url(search_term, data_filter=None):\n",
        "    \"\"\"\n",
        "    Generates the URL for the news search API request.\n",
        "\n",
        "    :param search_term: str, the term to search for in the news\n",
        "    :param data_filter: int, the number of days ago to filter the news by\n",
        "    :return: str, the URL for the API request\n",
        "    \"\"\"\n",
        "    base_url = 'https://news.google.com/rss/search?q='\n",
        "    search_url = base_url + search_term.replace(' ', '+')\n",
        "    if data_filter:\n",
        "        temp_time = (pd.datetime.today() - pd.Timedelta(days=data_filter)).strftime('%Y-%m-%d')\n",
        "        search_url += f'+after:{temp_time}'\n",
        "    return search_url\n",
        "\n",
        "\n",
        "def get_news(search_term, data_filter=None):\n",
        "    \"\"\"\n",
        "    Makes an API request to Google News and parses the XML response.\n",
        "\n",
        "    :param search_term: str, the term to search for in the news\n",
        "    :param data_filter: int, the number of days ago to filter the news by\n",
        "    :return: list of dicts, each dict containing information about a news article\n",
        "    \"\"\"\n",
        "    url = generate_search_url(search_term, data_filter)\n",
        "    response = requests.get(url)\n",
        "    root = ET.fromstring(response.content)\n",
        "    items = root.findall('./channel/item')\n",
        "    news_list = []\n",
        "    for item in items:\n",
        "        news_dict = {}\n",
        "        news_dict['title'] = item.find('title').text\n",
        "        news_dict['link'] = item.find('link').text\n",
        "        news_dict['description'] = item.find('description').text\n",
        "        news_dict['pubDate'] = item.find('pubDate').text\n",
        "        news_dict['source'] = item.find('source').text\n",
        "        news_list.append(news_dict)\n",
        "    return news_list\n",
        "\n",
        "\n",
        "def get_sentiment(text):\n",
        "    \"\"\"\n",
        "    Analyzes the sentiment of the text using TextBlob.\n",
        "\n",
        "    :param text: str, the text to analyze\n",
        "    :return: tuple, the sentiment polarity and subjectivity\n",
        "    \"\"\"\n",
        "    blob = TextBlob(text)\n",
        "    sentiment = blob.sentiment\n",
        "    return sentiment.polarity, sentiment.subjectivity\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    start_time = time.time()\n",
        "    search_term = input('Enter your search term here: ')\n",
        "    data_filter = int(input('Enter number of days ago or leave blank for all data: ')) or None\n",
        "    news_list = get_news(search_term, data_filter)\n",
        "\n",
        "    for news in news_list:\n",
        "        title = news['title']\n",
        "        description = news['description']\n",
        "        polarity, subjectivity = get_sentiment(description)\n",
        "        print(f\"Title: {title}\")\n",
        "        print(f\"Description: {description}\")\n",
        "        print(f\"Sentiment: Polarity={polarity:.2f}, Subjectivity={subjectivity:.2f}\\n\")\n",
        "    end_time = time.time()\n",
        "    print(f'Execution time: {end_time - start_time:.2f} seconds')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Q4tOMookahm"
      },
      "source": [
        "**Title & Description:** Sentiment Polarity Subjectivity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQwGo6alkYZ5"
      },
      "source": [
        "Title Polarity: This refers to the sentiment expressed in the title of the news article. The polarity is a score between -1.0 and 1.0. If the score is close to 1.0, it indicates that the title has a positive sentiment (positive words or phrases are used). If it's close to -1.0, the title has a negative sentiment (negative words or phrases are used). A score close to 0 suggests that the title is neutral.\n",
        "\n",
        "Title Subjectivity: This refers to the subjectivity of the title of the news article. The subjectivity is a score between 0.0 and 1.0. If the score is close to 1.0, it indicates that the title is highly subjective and might contain personal opinions or feelings. If it's close to 0, the title is more objective and focuses on factual information.\n",
        "\n",
        "Description Polarity: Similar to the Title Polarity, this refers to the sentiment expressed in the description or the main body of the news article. Again, a score close to 1.0 indicates positive sentiment, close to -1.0 indicates negative sentiment, and around 0 is neutral.\n",
        "\n",
        "Description Subjectivity: This refers to the subjectivity of the main content or description of the news article. Like Title Subjectivity, a score close to 1.0 means the description is highly subjective, and a score close to 0 means it is objective or factual.\n",
        "\n",
        "These scores can give you an understanding of both the emotional tone (polarity) and the presence of factual information vs. personal opinion (subjectivity) in news articles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcD1ln_ijimn"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "import time\n",
        "from textblob import TextBlob\n",
        "\n",
        "def generate_search_url(search_term, data_filter=None):\n",
        "    base_url = 'https://news.google.com/rss/search?q='\n",
        "    search_url = base_url + search_term.replace(' ', '+')\n",
        "    if data_filter:\n",
        "        temp_time = (pd.Timestamp.now() - pd.Timedelta(days=data_filter)).strftime('%Y-%m-%d')\n",
        "        search_url += f'+after:{temp_time}'\n",
        "    return search_url\n",
        "\n",
        "\n",
        "def get_news(search_term, data_filter=None):\n",
        "    url = generate_search_url(search_term, data_filter)\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "    except requests.exceptions.HTTPError as err:\n",
        "        print(f\"HTTP error occurred: {err}\")\n",
        "        return []\n",
        "    except requests.exceptions.RequestException as err:\n",
        "        print(f\"Error occurred: {err}\")\n",
        "        return []\n",
        "\n",
        "    root = ET.fromstring(response.content)\n",
        "    items = root.findall('./channel/item')\n",
        "    news_list = []\n",
        "    for item in items:\n",
        "        news_dict = {}\n",
        "        news_dict['title'] = item.find('title').text if item.find('title') is not None else ''\n",
        "        news_dict['link'] = item.find('link').text if item.find('link') is not None else ''\n",
        "        news_dict['description'] = item.find('description').text if item.find('description') is not None else ''\n",
        "        news_dict['pubDate'] = item.find('pubDate').text if item.find('pubDate') is not None else ''\n",
        "        news_dict['source'] = item.find('source').text if item.find('source') is not None else ''\n",
        "        news_list.append(news_dict)\n",
        "    return news_list\n",
        "\n",
        "\n",
        "def get_sentiment(text):\n",
        "    blob = TextBlob(text)\n",
        "    sentiment = blob.sentiment\n",
        "    return sentiment.polarity, sentiment.subjectivity\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    start_time = time.time()\n",
        "    search_term = input('Enter your search term here: ')\n",
        "    data_filter = int(input('Enter number of days ago or leave blank for all data: ')) or None\n",
        "    news_list = get_news(search_term, data_filter)\n",
        "    results = []\n",
        "\n",
        "    for news in news_list:\n",
        "        title = news['title']\n",
        "        description = news['description']\n",
        "        polarity_title, subjectivity_title = get_sentiment(title)\n",
        "        polarity_desc, subjectivity_desc = get_sentiment(description)\n",
        "        print(f\"Title: {title}\")\n",
        "        print(f\"Description: {description}\")\n",
        "        print(f\"Sentiment: Polarity={polarity_title:.2f}, Subjectivity={subjectivity_title:.2f} for the title\")\n",
        "        print(f\"Sentiment: Polarity={polarity_desc:.2f}, Subjectivity={subjectivity_desc:.2f} for the description\\n\")\n",
        "\n",
        "        # Saving results in a list\n",
        "        results.append([title, description, polarity_title, subjectivity_title, polarity_desc, subjectivity_desc])\n",
        "\n",
        "    # Converting the list to a DataFrame\n",
        "    df = pd.DataFrame(results, columns=['Title', 'Description', 'Title Polarity', 'Title Subjectivity', 'Description Polarity', 'Description Subjectivity'])\n",
        "\n",
        "    # Saving DataFrame to a CSV file\n",
        "    df.to_csv('news_sentiment_analysis.csv', index=False)\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f'Execution time: {end_time - start_time:.2f} seconds')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
